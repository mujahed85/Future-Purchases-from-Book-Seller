---
title: "Predicting Book Purchases"
author: "Rush, Daniel"
date: "January 14, 2018"
output:
  html_document: default
  pdf_document: default
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = TRUE)
```

# Loading Libraries and data

```{r, message=FALSE, warning=FALSE}
library(dplyr)
library(lubridate)
library(ggplot2)
library(caret)
library(pROC)
library(glmnet)

orders <- read.csv("orders.csv")
booktrain <- read.csv("booktrain.csv")
```

### Orders

```{r}
dim(orders)
head(orders)
str(orders)
```

### Booktrain

```{r}
dim(booktrain)
head(booktrain)
str(booktrain)
```

# Data Preprocessing

### Removing orders with category 99 and price 0

```{r}
orders_no99 <- orders %>% filter(category != '99') %>% filter(price != 0)
write.csv(orders_no99, "orders_no99.csv", row.names = FALSE)

orders <- orders_no99
```


```{r}
orders <- mutate(orders, orddate = dmy(orddate), category = factor(category))
```

### Partitioning into training and test sets
 
```{r}
length(orders$id)
length(unique(orders$id))
length(booktrain$id)
length(unique(booktrain$id))
```

The id's in `booktrain.csv` are all unique. This is not the case with `orders.csv`.

`orders.csv` has 33,355 unique ids. We need to partition the testing and training sets from `orders.csv`.

```{r}
train <- filter(orders, id %in% booktrain$id)
test <- filter(orders, !(id %in% booktrain$id))
```



## Basic EDA

Looking at the number of unique ids in `train` and `test`

```{r}
length(unique(train$id))
length(unique(test$id))
```

There are 87 ids in `booktrain` that are not present in `orders`.

```{r}
qplot(data = booktrain, x = logtarg)
```

How many customers responded?

```{r}
length(which(booktrain$logtarg>0))
```

Number of orders per customer in descending order.

```{r}
group_by(orders, id) %>% summarise(n = n_distinct(ordnum)) %>% arrange(desc(n))
```



## Feature creation


### Creating Aggregated Features

Creating these features in particular, number of orders and total sales per customer in the current year (2014), last year (2013), two years ago (2012), and total before that.

```{r}
this_year <- 2014
last_year <- 2013
ago2_year <- 2012

slstyr_df <- orders %>% 
    group_by(id) %>% 
    summarise(slstyr = sum(ifelse(year(orddate)==this_year, price*qty, 0)))

ordtyr_df <- orders %>% 
    group_by(id) %>% 
    summarise(ordtyr = sum(ifelse(year(orddate)==this_year, qty, 0)))

slslyr_df <- orders %>% 
    group_by(id) %>% 
    summarise(slslyr = sum(ifelse(year(orddate)==last_year, price*qty, 0)))

ordlyr_df <- orders %>% 
    group_by(id) %>% 
    summarise(ordlyr = sum(ifelse(year(orddate)==last_year, qty, 0)))


sls2ago_df <- orders %>% 
    group_by(id) %>% 
    summarise(sls2ago = sum(ifelse(year(orddate)==ago2_year, price*qty, 0)))

ord2ago_df <- orders %>% 
    group_by(id) %>% 
    summarise(ord2ago = sum(ifelse(year(orddate)==ago2_year, qty, 0)))


slsbfr_df <- orders %>% 
    group_by(id) %>% 
    summarise(slsbfr = sum(ifelse(year(orddate)<ago2_year, price*qty, 0)))

ordbfr_df <- orders %>% 
    group_by(id) %>% 
    summarise(ordbfr = sum(ifelse(year(orddate)<ago2_year, qty, 0)))

```


```{r}

# total number of orders per id

tot_orders_df <- group_by(orders, id) %>% summarise(tot_orders = 
                         n_distinct(ordnum))

# number of items purchased per order

avg_items_df <- group_by(orders, id) %>% summarise(avg_items = sum(qty)) %>% 
    mutate(avg_items = avg_items/tot_orders_df$tot_orders)

# average price per order

avg_price_df <- group_by(orders, id) %>% summarise(avg_price = sum(price*qty)) %>%
    mutate(avg_price = avg_price/tot_orders_df$tot_orders)


# total number of categories purchased

tot_cat_df <- group_by(orders, id) %>% summarise(tot_cat = n_distinct(category))
```


### Creating temporal features

```{r}
# first purchase date

first_pur_df = group_by(orders, id) %>% summarise(first_pur = min(orddate))

# last purchase date

last_pur_df = group_by(orders, id) %>% summarise(last_pur = max(orddate))

# total price of last purchase date

last_tot_price_df = group_by(orders, id, orddate) %>% 
    summarise(last_tot_price = sum(price*qty)) %>% 
    group_by(id) %>% 
    filter(orddate == max(orddate)) %>% 
    select(id, last_tot_price)
```

### Merging features into a dataframe

```{r}

# merging all features into temp df

temp_df <- Reduce(function(x, y) merge(x, y, by = "id"), list(tot_orders_df, avg_items_df, avg_price_df, tot_cat_df, first_pur_df, last_pur_df, last_tot_price_df, slstyr_df, slslyr_df, sls2ago_df, slsbfr_df, ordtyr_df, ordlyr_df, ord2ago_df, ordbfr_df))

# creating the following features
# 1. the average time between orders
# 2. activity defined as (lifetime - recency)/lifetime, which is the proportion of lifetime a customer was active
# 3. last order weighted by price

temp_df <- temp_df %>%
    mutate(pur_time_avg = as.integer(last_pur - first_pur)/tot_orders) %>%
    mutate(activity = as.integer(last_pur - first_pur)/
               as.integer(as.Date("2014-08-01") - first_pur)) %>%
    mutate(last_ord_wt = as.integer(as.Date("2014-08-01") - last_pur)*
               last_tot_price)

# removing last_tot_price now that we have created last_ord_wt

temp_df <- select(temp_df, -last_tot_price)

temp_df <- mutate(temp_df, last_pur = as.integer(last_pur), 
                  first_pur = as.integer(first_pur))
```

### Adding back the naive features

```{r}
naive_features <- group_by(orders, id) %>%
    summarise(tot_price = sum(price*qty), tot_qty = sum(qty))


temp_df <- merge(temp_df, naive_features, by = 'id')
```



### Partition into train and test sets and merge with response

```{r}
train_adv <- filter(temp_df, id %in% booktrain$id)
test_adv <- filter(temp_df, !(id %in% booktrain$id))


merged_train_adv <- merge(train_adv, booktrain, by = 'id')
write.csv(merged_train_adv, "merged_train_adv.csv", row.names = FALSE)
write.csv(test_adv, "test_adv.csv", row.names = FALSE)
```

# Training different Models

Now that we have created several features, we will train several models to see which ones work the best.

## Simple Linear Regression

```{r}
set.seed(2018-01-20)
tctrl <- trainControl(method = "cv", number = 10)
linear <- train(logtarg ~ .-id-tot_price-tot_qty, data = merged_train_adv, method = "lm", trControl = tctrl)
linear
```

**RMSE = `r linear$results["RMSE"]`**


## Linear Regression with all possible interactions


### Choosing the significant interactions among all possible with lasso

```{r}
all_mat <- model.matrix(logtarg ~ (.-id)^2-1, data = merged_train_adv)

lassocv <- cv.glmnet(all_mat, merged_train_adv$logtarg, alpha=1, 
                     nfold=10, lambda=seq(0,10,0.01))

lambdalasso <- lassocv$lambda.min

print(lambdalasso)

plot(lassocv)

small.lambda.index <- which(lassocv$lambda == lassocv$lambda.min)
small.lambda.betas <- coef(lassocv$glmnet.fit)[,small.lambda.index]
# print(small.lambda.betas)


# names(which(small.lambda.betas==0))
```

Lasso doesnt give good results. It fails to remove any of the predictors.

### Choosing the significant interactions among all possible with forward stepwise regression

```{r, message=FALSE, results="hide"}
linear_base <- lm(logtarg ~ 1, data = merged_train_adv)
biggest <- formula(lm(logtarg ~ (.-id)^2, data = merged_train_adv))
linear_fwd <- step(linear_base, direction = "both", scope = biggest)
```

Removing the most non significant predictor `activity` and doing backwards again,

```{r}
# removing activity and creating the new formula to pass to the model
frm <- as.formula(paste0(Reduce(paste0, deparse(formula(linear_fwd))), " - activity - slstyr - last_pur - ordlyr"))

linear_step_refined <- step(lm(frm, data = merged_train_adv), direction = "both")

summary(linear_step_refined)
```


#### Getting the cross validated RMSE 

Using the formula for forward stepwise to get cross validation results

```{r}
set.seed(2018-01-20)
linear_fwd_cv <- train(formula(linear_step_refined), data = merged_train_adv, method = "lm", trControl = tctrl)
linear_fwd_cv
```

**RMSE = `r linear_fwd_cv$results["RMSE"]`**



## Logistic Regression

### Simple logistic regression

```{r}
set.seed(2018-01-20)

merged_train_logistic <- mutate(merged_train_adv, 
                                responded = as.factor(ifelse(logtarg>0, 1, 0))) %>% 
    select(-logtarg)

levels(merged_train_logistic$responded) <- c("no", "yes")

tctrl_logistic <- trainControl(method = "cv", number = 10, classProbs = TRUE, 
                      summaryFunction = twoClassSummary)

logistic <- train(responded ~ .-id-tot_price-tot_qty, data = merged_train_logistic,
                method = "glm", family = binomial, trControl = tctrl_logistic, 
                metric = "ROC", maximize = TRUE)
logistic
```


**AUC = `r logistic$results['ROC']`**

### Logistic with all possible interactions


```{r, message=FALSE, results="hide"}


logistic_base <- glm(responded ~ 1, data = merged_train_logistic, family = binomial)

biggest_logistic <- formula(glm(responded ~ (.-id)^2, 
                                data = merged_train_logistic, family = binomial))

logistic_fwd <- step(logistic_base, direction = "both", scope = biggest_logistic)

summary(logistic_fwd)
```


### Cross validation on logistic regression

```{r}
set.seed(2018-01-20)
logistic_fwd_cv <- train(formula(logistic_fwd), data = merged_train_logistic,
                method = "glm", family = binomial, trControl = tctrl_logistic, 
                metric = "ROC", maximize = TRUE)
logistic_fwd_cv
```

**AUC = `r logistic_fwd_cv$results['ROC']`**

This gave a better AUC than before.


## Linear model on only `responded = TRUE`

### Simple linear model

```{r}
merged_train_linear <- filter(merged_train_adv, logtarg>0)
set.seed(2018-01-20)
tctrl <- trainControl(method = "cv", number = 10)
linear2 <- train(logtarg ~ .-id-tot_price-tot_qty, data = merged_train_linear, method = "lm", trControl = tctrl)
linear2
```


### Linear model with all interactions

```{r, message=FALSE, results="hide"}
linear_base <- lm(logtarg ~ 1, data = merged_train_adv)
biggest <- formula(lm(logtarg ~ (.-id)^2, data = merged_train_linear))
linear_fwd <- step(linear_base, direction = "both", scope = biggest)
summary(linear_fwd)
```

We find that the linear model trained on the subset of the data picks the same features as the one trained on the entire training data.

```{r}
set.seed(2018-01-20)
linear2_fwd_cv <- train(formula(linear_step_refined), data = merged_train_linear,
                        method = "lm", trControl = tctrl)
linear2_fwd_cv
```


# Making predictions

## With only linear with all possible interactions

```{r}
pred_linear <- predict(linear_fwd_cv, test_adv)
write.csv(data.frame(id = test_adv$id, yhat = pred_linear),
          "only_linear_regression.csv", row.names = FALSE)
```

## With logistic plus linear

```{r}
pred_logistic <- predict(logistic_fwd, test_adv, type = "response")

pred_linear2 <- predict(linear2_fwd_cv, test_adv)

# imposing a hard threshold on the linear model to keep the extreme values in check

pred_linear2 <- ifelse(pred_linear2>20, 20, pred_linear2)

pred_linear2 <- ifelse(pred_linear2<0, 0, pred_linear2)

# generating the final submission file using the linear and logistic model

write.csv(data.frame(id = test_adv$id, yhat = pred_logistic * pred_linear2),
          "linear_plus_logistic.csv", row.names = FALSE)
```

