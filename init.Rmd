---
title: "Predicting Book Purchases"
author: "Rush"
date: "January 14, 2018"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Loading Libraries and data

```{r}
setwd("F:/MSIA/Winter 2018/MSiA 421 - Data Mining/kaggle")

library(dplyr)
library(lubridate)
library(ggplot2)

orders <- read.csv("orders.csv")
booktrain <- read.csv("booktrain.csv")
```

### Orders

```{r}
dim(orders)
head(orders)
str(orders)
```

### Booktrain

```{r}
dim(booktrain)
head(booktrain)
str(booktrain)
```

## Data Preprocessing

```{r}
orders <- mutate(orders, orddate = dmy(orddate), category = factor(category))
```

### Partitioning into training and test sets
 
```{r}
length(orders$id)
length(unique(orders$id))
length(booktrain$id)
length(unique(booktrain$id))
```

The id's in `booktrain.csv` are all unique. This is not the case with `orders.csv`.

`orders.csv` has 33,355 unique ids. We need to partition the testing and training sets from `orders.csv`.

```{r}
train <- filter(orders, id %in% booktrain$id)
test <- filter(orders, !(id %in% booktrain$id))
```

Looking at the number of unique ids in `train` and `test`

```{r}
length(unique(train$id))
length(unique(test$id))
```

There are 87 ids in `booktrain` that are not present in `orders`.


### EDA

```{r}
qplot(data = booktrain, x = logtarg)
```

How many customers responded?

```{r}
length(which(booktrain$logtarg>0))
```

Number of orders per customer in descending order.

```{r}
group_by(orders, id) %>% summarise(n = n_distinct(ordnum)) %>% arrange(desc(n))
```


## Naive model

```{r}
naive_df_train <- group_by(train, id) %>%
    summarise(tot_price = sum(price), tot_qty = sum(qty))

merged_train = merge(naive_df_train, booktrain, by = 'id')

naive_df_test <- group_by(test, id) %>%
    summarise(tot_price = sum(price), tot_qty = sum(qty))
```


fitting the linear model

```{r}
naive_fit <- lm(logtarg ~ . -id, data = merged_train)
summary(naive_fit)
```

prediction

```{r}
pred <- predict(naive_fit, newdata = naive_df_test)
predictions <- data.frame(id = naive_df_test$id, yhat = pred)
write.csv(predictions, file = 'naive.csv', row.names = FALSE)
```



## Feature creation

### Creating aggregated features

```{r}

# total number of orders per id

tot_orders_df <- group_by(orders, id) %>% summarise(tot_orders = 
                         n_distinct(ordnum))

# number of items purchased per order

avg_items_df <- group_by(orders, id) %>% summarise(avg_items = sum(qty)) %>% 
    mutate(avg_items = avg_items/tot_orders_df$tot_orders)

# average price per order

avg_price_df <- group_by(orders, id) %>% summarise(avg_price = sum(price)) %>%
    mutate(avg_price = avg_price/tot_orders_df$tot_orders)


# total number of categories purchased

tot_cat_df <- group_by(orders, id) %>% summarise(tot_cat = n_distinct(category))
```


### Creating temporal features

```{r}
# first purchase date

first_pur_df = group_by(orders, id) %>% summarise(first_pur = min(orddate))

# last purchase date

last_pur_df = group_by(orders, id) %>% summarise(last_pur = max(orddate))

# total price of last purchase date

last_tot_price_df = group_by(orders, id, orddate) %>% 
    summarise(last_tot_price = sum(price)) %>% 
    group_by(id) %>% 
    filter(orddate == max(orddate)) %>% 
    select(id, last_tot_price)
```

### Merging features into a dataframe

```{r}

# merging all features into temp df

temp_df <- Reduce(function(x, y) merge(x, y, by = "id"), list(tot_orders_df, avg_items_df, avg_price_df, tot_cat_df, first_pur_df, last_pur_df, last_tot_price_df))

# creating the following features
# 1. the average time between orders
# 2. activity defined as (lifetime - recency)/lifetime, which is the proportion of lifetime a customer was active
# 3. last order weighted by price

temp_df <- temp_df %>%
    mutate(pur_time_avg = as.integer(last_pur - first_pur)/tot_orders) %>%
    mutate(activity = as.integer(last_pur - first_pur)/
               as.integer(as.Date("2014-08-01") - first_pur)) %>%
    mutate(last_ord_wt = as.integer(as.Date("2014-08-01") - last_pur)*
               last_tot_price)

# removing last_tot_price now that we have created last_ord_wt

temp_df <- select(temp_df, -last_tot_price)

temp_df <- mutate(temp_df, last_pur = as.integer(last_pur), 
                  first_pur = as.integer(first_pur))
```

### Adding back the naive features

```{r}
naive_features <- group_by(orders, id) %>%
    summarise(tot_price = sum(price), tot_qty = sum(qty))


temp_df <- merge(temp_df, naive_features, by = 'id')
```



### Partition into train and test sets and merge with response

```{r}
train_adv <- filter(temp_df, id %in% booktrain$id)
test_adv <- filter(temp_df, !(id %in% booktrain$id))


merged_train_adv <- merge(train_adv, booktrain, by = 'id')
```



## Fitting the model

```{r}
adv_fit <- lm(logtarg ~ .-id, data = merged_train_adv)
summary(adv_fit)
```




