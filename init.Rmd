---
title: "Predicting Book Purchases"
author: "Rush"
date: "January 14, 2018"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Loading Libraries and data

```{r}
setwd("F:/MSIA/Winter 2018/MSiA 421 - Data Mining/kaggle")

library(dplyr)
library(lubridate)
library(ggplot2)

orders <- read.csv("orders.csv")
booktrain <- read.csv("booktrain.csv")
```

### Orders

```{r}
dim(orders)
head(orders)
str(orders)
```

### Booktrain

```{r}
dim(booktrain)
head(booktrain)
str(booktrain)
```

## Data Preprocessing

```{r}
orders <- mutate(orders, orddate = dmy(orddate), category = factor(category))
```

### Partitioning into training and test sets
 
```{r}
length(orders$id)
length(unique(orders$id))
length(booktrain$id)
length(unique(booktrain$id))
```

The id's in `booktrain.csv` are all unique. This is not the case with `orders.csv`.

`orders.csv` has 33,355 unique ids. We need to partition the testing and training sets from `orders.csv`.

```{r}
train <- filter(orders, id %in% booktrain$id)
test <- filter(orders, !(id %in% booktrain$id))
```

Looking at the number of unique ids in `train` and `test`

```{r}
length(unique(train$id))
length(unique(test$id))
```

There are 87 ids in `booktrain` that are not present in `orders`.


### EDA

```{r}
qplot(data = booktrain, x = logtarg)
```

How many customers responded?

```{r}
length(which(booktrain$logtarg>0))
```

Number of orders per customer in descending order.

```{r}
group_by(orders, id) %>% summarise(n = n_distinct(ordnum)) %>% arrange(desc(n))
```


## Naive model

```{r}
naive_df_train <- group_by(train, id) %>%
    summarise(tot_price = sum(price), tot_qty = sum(qty))

merged_train_naive = merge(naive_df_train, booktrain, by = 'id')

naive_df_test <- group_by(test, id) %>%
    summarise(tot_price = sum(price), tot_qty = sum(qty))
```


fitting the linear model

```{r}
naive_fit <- lm(logtarg ~ . -id, data = merged_train_naive)
summary(naive_fit)
```

prediction

```{r}
pred <- predict(naive_fit, newdata = naive_df_test)
predictions <- data.frame(id = naive_df_test$id, yhat = pred)
write.csv(predictions, file = 'naive.csv', row.names = FALSE)
```



## Feature creation

### Removing bad entries

```{r}
# removing zero priced purchases
# orders <- filter(orders, price != 0)

```


### Creating aggregated features

```{r}

# total number of orders per id

tot_orders_df <- group_by(orders, id) %>% summarise(tot_orders = 
                         n_distinct(ordnum))

# number of items purchased per order

avg_items_df <- group_by(orders, id) %>% summarise(avg_items = sum(qty)) %>% 
    mutate(avg_items = avg_items/tot_orders_df$tot_orders)

# average price per order

avg_price_df <- group_by(orders, id) %>% summarise(avg_price = sum(price)) %>%
    mutate(avg_price = avg_price/tot_orders_df$tot_orders)


# total number of categories purchased

tot_cat_df <- group_by(orders, id) %>% summarise(tot_cat = n_distinct(category))
```


### Creating temporal features

```{r}
# first purchase date

first_pur_df = group_by(orders, id) %>% summarise(first_pur = min(orddate))

# last purchase date

last_pur_df = group_by(orders, id) %>% summarise(last_pur = max(orddate))

# total price of last purchase date

last_tot_price_df = group_by(orders, id, orddate) %>% 
    summarise(last_tot_price = sum(price)) %>% 
    group_by(id) %>% 
    filter(orddate == max(orddate)) %>% 
    select(id, last_tot_price)
```

### Merging features into a dataframe

```{r}

# merging all features into temp df

temp_df <- Reduce(function(x, y) merge(x, y, by = "id"), list(tot_orders_df, avg_items_df, avg_price_df, tot_cat_df, first_pur_df, last_pur_df, last_tot_price_df))

# creating the following features
# 1. the average time between orders
# 2. activity defined as (lifetime - recency)/lifetime, which is the proportion of lifetime a customer was active
# 3. last order weighted by price

temp_df <- temp_df %>%
    mutate(pur_time_avg = as.integer(last_pur - first_pur)/tot_orders) %>%
    mutate(activity = as.integer(last_pur - first_pur)/
               as.integer(as.Date("2014-08-01") - first_pur)) %>%
    mutate(last_ord_wt = as.integer(as.Date("2014-08-01") - last_pur)*
               last_tot_price)

# removing last_tot_price now that we have created last_ord_wt

temp_df <- select(temp_df, -last_tot_price)

temp_df <- mutate(temp_df, last_pur = as.integer(last_pur), 
                  first_pur = as.integer(first_pur))
```

### Adding back the naive features

```{r}
naive_features <- group_by(orders, id) %>%
    summarise(tot_price = sum(price), tot_qty = sum(qty))


temp_df <- merge(temp_df, naive_features, by = 'id')
```



### Partition into train and test sets and merge with response

```{r}
train_adv <- filter(temp_df, id %in% booktrain$id)
test_adv <- filter(temp_df, !(id %in% booktrain$id))


merged_train_adv <- merge(train_adv, booktrain, by = 'id')
```



## Fitting the model

```{r}
adv_fit <- lm(logtarg ~ .-id, data = merged_train_adv)
summary(adv_fit)
```

### Generate csv for submission

```{r}
pred_adv <- predict(adv_fit, newdata = test_adv)
predictions_adv <- data.frame(id = test_adv$id, yhat = pred_adv)
write.csv(predictions_adv, file = 'adv.csv', row.names = FALSE)
```



## Cross validation

### Naive model

```{r}
tctrl = trainControl(method = "cv", number = 10)
mod_naive = train(logtarg ~ .-id, data = merged_train_naive, method = "lm", trControl = tctrl)
mod_naive

```


### Advanced model
```{r}
tctrl = trainControl(method = "cv", number = 10)
mod_adv = train(logtarg ~ .-id, data = merged_train_adv, method = "lm", trControl = tctrl)
mod_adv
```

## Ajit's Method

### Logistic Modeling

```{r}
merged_train_logistic <- mutate(merged_train_adv, 
                                responded = ifelse(logtarg>0, 1, 0)) %>%
    select(-logtarg)

logfit <- glm(responded ~ .-id, data = merged_train_logistic, family = binomial)
summary(logfit)
```


```{r}
merged_train_linear <- filter(merged_train_adv, logtarg>0)
ajit_fit <- lm(logtarg ~ .-id, data = merged_train_linear)
summary(ajit_fit)
```


## Prediction using Ajit's models

```{r}
pred_linear_ajit <- predict(ajit_fit, newdata = test_adv)
pred_logistic_ajit <- predict(logfit, newdata = test_adv, type="response")

predictions_ajit <- data.frame(id = test_adv$id, 
                               yhat = pred_linear_ajit*pred_logistic_ajit)
write.csv(predictions_ajit, file = 'ajit.csv', row.names = FALSE)
```



## Cross validation for Ajit's method

```{r}
# set.seed(2018-1-16)

equal0 <- filter(merged_train_adv, logtarg==0)
greater0 <- filter(merged_train_adv, logtarg>0)

equal0 <- equal0[sample(1:nrow(equal0)), ]
greater0 <- greater0[sample(1:nrow(greater0)), ]

erows <- nrow(equal0)/10
grows <- nrow(greater0)/10

results <- c()

for(i in 0:9){
    
    equal_k <- equal0[-((floor(i*erows)+1):(floor((i+1)*erows))),]
    greater_k <- greater0[-((floor(i*grows)+1):(floor((i+1)*grows))),]
    
    merged_k <- rbind(equal_k, greater_k)
        
        
    merged_train_logistic_k <- mutate(merged_k, 
                                responded = ifelse(logtarg>0, 1, 0)) %>% 
        select(-logtarg)

    logfit_k <- glm(responded ~ .-id, data = merged_train_logistic_k, 
                    family = binomial)
    
    linear_k <- lm(logtarg ~ .-id, data = greater_k)
    
    test_equal_k <- equal0[(floor(i*erows)+1):(floor((i+1)*erows)),]
    test_greater_k <- greater0[(floor(i*grows)+1):(floor((i+1)*grows)),]
    test_merged_k <- rbind(test_equal_k, test_greater_k)
    
    pred_linear_k <- predict(linear_k, newdata = test_merged_k)
    pred_logistic_k <- predict(logfit_k, newdata = test_merged_k, type="response")

    predictions_k <- data.frame(id = test_merged_k$id, 
                               yhat = pred_linear_k*pred_logistic_k)
    
    error_k <- sum((test_merged_k$logtarg-predictions_k$yhat)^2)/nrow(test_merged_k)
    error_k <- sqrt(error_k)
    
    results <- c(results, error_k)
}

mean(results)
```


## Modified Ajit's method

```{r}
merged_train_logistic <- mutate(merged_train_adv, 
                                responded = ifelse(logtarg>0, 1, 0)) %>%
    select(-logtarg)

modified_logfit <- glm(responded ~ .-id, data = merged_train_logistic, family = binomial)
summary(modified_logfit)
```


```{r}
modified_ajit_fit <- lm(logtarg ~ .-id, data = merged_train_adv)
summary(modified_ajit_fit)
```


## Prediction using Modified Ajit's models

```{r}
mod_pred_linear_ajit <- predict(modified_ajit_fit, newdata = test_adv)
mod_pred_logistic_ajit <- predict(modified_logfit, newdata = test_adv, type="response")

modified_predictions_ajit <- data.frame(id = test_adv$id, 
                               yhat = mod_pred_linear_ajit*mod_pred_logistic_ajit)
write.csv(modified_predictions_ajit, file = 'mod_ajit.csv', row.names = FALSE)
```


## Cross validation for modified ajit's method

```{r}
# set.seed(2018-1-16)
merged_train_adv <- merged_train_adv[sample(1:nrow(merged_train_adv)), ]
rows <- nrow(merged_train_adv)/10

mod_results <- c()

for(i in 0:9){
    
    merged_k <- merged_train_adv[-((floor(i*rows)+1):(floor((i+1)*rows))),]
        
    merged_train_logistic_k <- mutate(merged_k, 
                                responded = ifelse(logtarg>0, 1, 0)) %>% 
        select(-logtarg)

    logfit_k <- glm(responded ~ .-id, data = merged_train_logistic_k, 
                    family = binomial)
    
    linear_k <- lm(logtarg ~ .-id, data = merged_k)
    
    test_merged_k <- merged_train_adv[(floor(i*rows)+1):(floor((i+1)*rows)),]
    
    pred_linear_k <- predict(linear_k, newdata = test_merged_k)
    pred_logistic_k <- predict(logfit_k, newdata = test_merged_k, type="response")

    predictions_k <- data.frame(id = test_merged_k$id, 
                               yhat = pred_linear_k*pred_logistic_k)
    
    error_k <- sum((test_merged_k$logtarg-predictions_k$yhat)^2)/nrow(test_merged_k)
    error_k <- sqrt(error_k)
    
    mod_results <- c(mod_results, error_k)
}

mean(mod_results)
```

